<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SpringBoot系列(一)</title>
    <url>/2020/02/15/SpringBoot%E7%B3%BB%E5%88%97-%E4%B8%80/</url>
    <content><![CDATA[<h1 id="SpringBoot简介"><a href="#SpringBoot简介" class="headerlink" title="SpringBoot简介"></a>SpringBoot简介</h1><h2 id="作为一个程序员SpringBoot这个框架你一定听过，SpringBoot让我们更方便的进行开发，一句来说就是SpringBoot让我们减少了配置文件的配置，起设计目的是用来简化新SpringBoot应用的初始化搭建以及开发过程。"><a href="#作为一个程序员SpringBoot这个框架你一定听过，SpringBoot让我们更方便的进行开发，一句来说就是SpringBoot让我们减少了配置文件的配置，起设计目的是用来简化新SpringBoot应用的初始化搭建以及开发过程。" class="headerlink" title="作为一个程序员SpringBoot这个框架你一定听过，SpringBoot让我们更方便的进行开发，一句来说就是SpringBoot让我们减少了配置文件的配置，起设计目的是用来简化新SpringBoot应用的初始化搭建以及开发过程。"></a>作为一个程序员SpringBoot这个框架你一定听过，SpringBoot让我们更方便的进行开发，一句来说就是SpringBoot让我们减少了配置文件的配置，起设计目的是用来简化新SpringBoot应用的初始化搭建以及开发过程。</h2><a id="more"></a>

<h1 id="SpringBoot特点"><a href="#SpringBoot特点" class="headerlink" title="SpringBoot特点"></a>SpringBoot特点</h1><h2 id="SpringBoot所具备的特征有："><a href="#SpringBoot所具备的特征有：" class="headerlink" title="SpringBoot所具备的特征有："></a>SpringBoot所具备的特征有：</h2><p>（1）可以创建独立的Spring应用程序，并且基于其Maven或Gradle插件，可以创建可执行的JARs和WARs；<br>（2）内嵌Tomcat或Jetty等Servlet容器；<br>（3）提供自动配置的“starter”项目对象模型（POMS）以简化Maven配置；<br>（4）尽可能自动配置Spring容器；<br>（5）提供准备好的特性，如指标、健康检查和外部化配置；<br>（6）绝对没有代码生成，不需要XML配置。</p>
<h1 id="使用SpringBoot"><a href="#使用SpringBoot" class="headerlink" title="使用SpringBoot"></a>使用SpringBoot</h1><h2 id="要想使用SpringBoot要在IDE中创建一个SpringBoot工程，创建完毕之后呢要先导入SpringBoot的依赖才能正常使用。"><a href="#要想使用SpringBoot要在IDE中创建一个SpringBoot工程，创建完毕之后呢要先导入SpringBoot的依赖才能正常使用。" class="headerlink" title="要想使用SpringBoot要在IDE中创建一个SpringBoot工程，创建完毕之后呢要先导入SpringBoot的依赖才能正常使用。"></a>要想使用SpringBoot要在IDE中创建一个SpringBoot工程，创建完毕之后呢要先导入SpringBoot的依赖才能正常使用。</h2><h2 id="在所在的项目的pom-xml中导入以下依赖："><a href="#在所在的项目的pom-xml中导入以下依赖：" class="headerlink" title="在所在的项目的pom.xml中导入以下依赖："></a>在所在的项目的pom.xml中导入以下依赖：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;parent&gt;</span><br><span class="line">	&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;spring-boot-starter-parent&lt;&#x2F;artifactId&gt;</span><br><span class="line">	&lt;version&gt;1.5.2.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;parent&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
<p>第一个&lt;parent&gt;依赖是SpringBoot最最核心的依赖，他是一个SpringBoot的父级依赖，它用来提供相关的Maven默认的依赖，SpringBoot的版本控制中心，正是它可以使我们方便的创建应用，不需要一个一个的配置依赖。</p>
<p>第二个&lt;dependency&gt;是SpringBoot的场景启动器，web的场景，自动帮我们引入了web模块开发需要的相关jar包</p>
<p>当我们导入以上依赖，我们就有了我们的一个SpringBoot程序</p>
]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop系列-HDFS（二）</title>
    <url>/2019/12/17/Hadoop%E7%B3%BB%E5%88%97-HDFS%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<!--     内容开始        -->


<!--  正文标题   -->


<!-- 正文内容 -->

<h1 id="HDFS安全模式"><a href="#HDFS安全模式" class="headerlink" title="HDFS安全模式"></a>HDFS安全模式</h1><h2 id="在启动的时候，名字节点进入一个叫做安全模式的特殊状态。安全模式中不允许发生文件块的复制。名字节点接受来自数据节点的心跳和块报告。一个块报告包含数据节点所拥有的数据块的列表。"><a href="#在启动的时候，名字节点进入一个叫做安全模式的特殊状态。安全模式中不允许发生文件块的复制。名字节点接受来自数据节点的心跳和块报告。一个块报告包含数据节点所拥有的数据块的列表。" class="headerlink" title="在启动的时候，名字节点进入一个叫做安全模式的特殊状态。安全模式中不允许发生文件块的复制。名字节点接受来自数据节点的心跳和块报告。一个块报告包含数据节点所拥有的数据块的列表。"></a>在启动的时候，名字节点进入一个叫做安全模式的特殊状态。安全模式中不允许发生文件块的复制。名字节点接受来自数据节点的心跳和块报告。一个块报告包含数据节点所拥有的数据块的列表。</h2><h3 id="每一个块有一个特定的最小复制数。当名字节点检查这个块已经大于最小的复制数就被认为是安全地复制了，当达到配置的块安全复制比例时（加上额外的30秒），名字节点就退出安全模式。它将检测数据块的列表，将小于特定复制数的块复制到其他的数据节点。"><a href="#每一个块有一个特定的最小复制数。当名字节点检查这个块已经大于最小的复制数就被认为是安全地复制了，当达到配置的块安全复制比例时（加上额外的30秒），名字节点就退出安全模式。它将检测数据块的列表，将小于特定复制数的块复制到其他的数据节点。" class="headerlink" title="每一个块有一个特定的最小复制数。当名字节点检查这个块已经大于最小的复制数就被认为是安全地复制了，当达到配置的块安全复制比例时（加上额外的30秒），名字节点就退出安全模式。它将检测数据块的列表，将小于特定复制数的块复制到其他的数据节点。"></a>每一个块有一个特定的最小复制数。当名字节点检查这个块已经大于最小的复制数就被认为是安全地复制了，当达到配置的块安全复制比例时（加上额外的30秒），名字节点就退出安全模式。它将检测数据块的列表，将小于特定复制数的块复制到其他的数据节点。</h3><a id="more"></a>

<h1 id="文件系统的元数据的持久化"><a href="#文件系统的元数据的持久化" class="headerlink" title="文件系统的元数据的持久化"></a>文件系统的元数据的持久化</h1><h2 id="HDFS的命名空间是由名字节点来存储的。名字节点使用叫做EditLog的事务日志来持久记录每一个对文件系统元数据的改变，如在HDFS中创建一个新的文件，名字节点将会在EditLog中插入一条记录来记录这个改变。类似地，改变文件的复制因子也会向EditLog中插入一条记录。名字节点在本地文件系统中用一个文件来存储这个EditLog。整个文件系统命名空间，包括文件块的映射表和文件系统的配置都存在一个叫FsImage的文件中，FsImage也存放在名字节点的本地文件系统中。"><a href="#HDFS的命名空间是由名字节点来存储的。名字节点使用叫做EditLog的事务日志来持久记录每一个对文件系统元数据的改变，如在HDFS中创建一个新的文件，名字节点将会在EditLog中插入一条记录来记录这个改变。类似地，改变文件的复制因子也会向EditLog中插入一条记录。名字节点在本地文件系统中用一个文件来存储这个EditLog。整个文件系统命名空间，包括文件块的映射表和文件系统的配置都存在一个叫FsImage的文件中，FsImage也存放在名字节点的本地文件系统中。" class="headerlink" title="HDFS的命名空间是由名字节点来存储的。名字节点使用叫做EditLog的事务日志来持久记录每一个对文件系统元数据的改变，如在HDFS中创建一个新的文件，名字节点将会在EditLog中插入一条记录来记录这个改变。类似地，改变文件的复制因子也会向EditLog中插入一条记录。名字节点在本地文件系统中用一个文件来存储这个EditLog。整个文件系统命名空间，包括文件块的映射表和文件系统的配置都存在一个叫FsImage的文件中，FsImage也存放在名字节点的本地文件系统中。"></a>HDFS的命名空间是由名字节点来存储的。名字节点使用叫做EditLog的事务日志来持久记录每一个对文件系统元数据的改变，如在HDFS中创建一个新的文件，名字节点将会在EditLog中插入一条记录来记录这个改变。类似地，改变文件的复制因子也会向EditLog中插入一条记录。名字节点在本地文件系统中用一个文件来存储这个EditLog。整个文件系统命名空间，包括文件块的映射表和文件系统的配置都存在一个叫FsImage的文件中，FsImage也存放在名字节点的本地文件系统中。</h2><h2 id="名字节点在内存中保留一个完整的文件系统命名空间和文件块的映射表的镜像。这个元数据被设计成紧凑的，这样4GB内存的名字节点就足以处理非常大的文件数和目录。名字节点启动时，它将从磁盘中读取FsImage和EditLog，将EditLog中的所有事务应用到FsImage的仿内存空间，然后将新的FsImage刷新到本地磁盘中，因为事务已经被处理并已经持久化的FsImage中，然后就可以截去旧的EditLog。这个过程叫做检查点。当前实现中，检查点仅在名字节点启动的时候发生，正在支持周期性的检查点。"><a href="#名字节点在内存中保留一个完整的文件系统命名空间和文件块的映射表的镜像。这个元数据被设计成紧凑的，这样4GB内存的名字节点就足以处理非常大的文件数和目录。名字节点启动时，它将从磁盘中读取FsImage和EditLog，将EditLog中的所有事务应用到FsImage的仿内存空间，然后将新的FsImage刷新到本地磁盘中，因为事务已经被处理并已经持久化的FsImage中，然后就可以截去旧的EditLog。这个过程叫做检查点。当前实现中，检查点仅在名字节点启动的时候发生，正在支持周期性的检查点。" class="headerlink" title="名字节点在内存中保留一个完整的文件系统命名空间和文件块的映射表的镜像。这个元数据被设计成紧凑的，这样4GB内存的名字节点就足以处理非常大的文件数和目录。名字节点启动时，它将从磁盘中读取FsImage和EditLog，将EditLog中的所有事务应用到FsImage的仿内存空间，然后将新的FsImage刷新到本地磁盘中，因为事务已经被处理并已经持久化的FsImage中，然后就可以截去旧的EditLog。这个过程叫做检查点。当前实现中，检查点仅在名字节点启动的时候发生，正在支持周期性的检查点。"></a>名字节点在内存中保留一个完整的文件系统命名空间和文件块的映射表的镜像。这个元数据被设计成紧凑的，这样4GB内存的名字节点就足以处理非常大的文件数和目录。名字节点启动时，它将从磁盘中读取FsImage和EditLog，将EditLog中的所有事务应用到FsImage的仿内存空间，然后将新的FsImage刷新到本地磁盘中，因为事务已经被处理并已经持久化的FsImage中，然后就可以截去旧的EditLog。这个过程叫做检查点。当前实现中，检查点仅在名字节点启动的时候发生，正在支持周期性的检查点。</h2><h2 id="数据节点将HDFS数据存储到本地的文件系统中。数据节点并不知道HDFS文件的存在，它在本地文件系统中以单独的文件存储每一个HDFS文件的数据块。数据节点不会将所有的数据块文件存放到同一个目录中，而是启发式的检测每一个目录的最优文件数，并在适当的时候创建子目录。在本地同一个目录下创建所有的数据块文件不是最优的，因为本地文件系统可能不支持单个目录下巨额文件的高效操作。当数据节点启动的时候，它将扫描它的本地文件系统，根据本地的文件产生一个所有HDFS数据块的列表并报告给名字节点，这个报告称作块报告。"><a href="#数据节点将HDFS数据存储到本地的文件系统中。数据节点并不知道HDFS文件的存在，它在本地文件系统中以单独的文件存储每一个HDFS文件的数据块。数据节点不会将所有的数据块文件存放到同一个目录中，而是启发式的检测每一个目录的最优文件数，并在适当的时候创建子目录。在本地同一个目录下创建所有的数据块文件不是最优的，因为本地文件系统可能不支持单个目录下巨额文件的高效操作。当数据节点启动的时候，它将扫描它的本地文件系统，根据本地的文件产生一个所有HDFS数据块的列表并报告给名字节点，这个报告称作块报告。" class="headerlink" title="数据节点将HDFS数据存储到本地的文件系统中。数据节点并不知道HDFS文件的存在，它在本地文件系统中以单独的文件存储每一个HDFS文件的数据块。数据节点不会将所有的数据块文件存放到同一个目录中，而是启发式的检测每一个目录的最优文件数，并在适当的时候创建子目录。在本地同一个目录下创建所有的数据块文件不是最优的，因为本地文件系统可能不支持单个目录下巨额文件的高效操作。当数据节点启动的时候，它将扫描它的本地文件系统，根据本地的文件产生一个所有HDFS数据块的列表并报告给名字节点，这个报告称作块报告。"></a>数据节点将HDFS数据存储到本地的文件系统中。数据节点并不知道HDFS文件的存在，它在本地文件系统中以单独的文件存储每一个HDFS文件的数据块。数据节点不会将所有的数据块文件存放到同一个目录中，而是启发式的检测每一个目录的最优文件数，并在适当的时候创建子目录。在本地同一个目录下创建所有的数据块文件不是最优的，因为本地文件系统可能不支持单个目录下巨额文件的高效操作。当数据节点启动的时候，它将扫描它的本地文件系统，根据本地的文件产生一个所有HDFS数据块的列表并报告给名字节点，这个报告称作块报告。</h2>]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop系列-HDFS（一）</title>
    <url>/2019/12/17/Hadoop%E7%B3%BB%E5%88%97-HDFS%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<!--     内容开始        -->


<!--  正文标题   -->
<h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><!-- 正文内容 -->
<h2 id="Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。"><a href="#Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。" class="headerlink" title="Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。"></a>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。</h2><h2 id="Hadoop特点"><a href="#Hadoop特点" class="headerlink" title="Hadoop特点"></a>Hadoop特点</h2><h3 id="一，高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。"><a href="#一，高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。" class="headerlink" title="一，高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。"></a>一，高可靠性。Hadoop按位存储和处理数据的能力值得人们信赖。</h3><h3 id="二，高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。"><a href="#二，高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。" class="headerlink" title="二，高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。"></a>二，高扩展性。Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</h3><h3 id="三，高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。"><a href="#三，高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。" class="headerlink" title="三，高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。"></a>三，高效性。Hadoop能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。</h3><h3 id="四，高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。"><a href="#四，高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。" class="headerlink" title="四，高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。"></a>四，高容错性。Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</h3><h3 id="五，低成本。与一体机、商用数据仓库以及QlikView、Yonghong，Z-Suite等数据集市相比，hadoop是开源的，项目的软件成-本因此会大大降低。"><a href="#五，低成本。与一体机、商用数据仓库以及QlikView、Yonghong，Z-Suite等数据集市相比，hadoop是开源的，项目的软件成-本因此会大大降低。" class="headerlink" title="五，低成本。与一体机、商用数据仓库以及QlikView、Yonghong，Z-Suite等数据集市相比，hadoop是开源的，项目的软件成        本因此会大大降低。"></a>五，低成本。与一体机、商用数据仓库以及QlikView、Yonghong，Z-Suite等数据集市相比，hadoop是开源的，项目的软件成        本因此会大大降低。</h3><a id="more"></a>
<h1 id="Hadoop核心架构"><a href="#Hadoop核心架构" class="headerlink" title="Hadoop核心架构"></a>Hadoop核心架构</h1><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1576757124160&di=376975b15de25ef3108e627b4dfcb1a5&imgtype=0&src=http%3A%2F%2Fwww.cbdio.com%2Fimage%2Fattachement%2Fpng%2Fsite2%2F20170703%2Fa41f7295e5de1ac3f78f08.png" alt="Hadoop" title="Hadoop架构"></p>
<h2 id="Hadoop-由许多元素构成。其最底部是-Hadoop-Distributed-File-System（HDFS），它存储-Hadoop-集群中所有存储节点上的文件。说到这里我们要详细的了解一下什么是HDFS？？？"><a href="#Hadoop-由许多元素构成。其最底部是-Hadoop-Distributed-File-System（HDFS），它存储-Hadoop-集群中所有存储节点上的文件。说到这里我们要详细的了解一下什么是HDFS？？？" class="headerlink" title="Hadoop 由许多元素构成。其最底部是 Hadoop Distributed File System（HDFS），它存储 Hadoop 集群中所有存储节点上的文件。说到这里我们要详细的了解一下什么是HDFS？？？"></a>Hadoop 由许多元素构成。其最底部是 Hadoop Distributed File System（HDFS），它存储 Hadoop 集群中所有存储节点上的文件。说到这里我们要详细的了解一下什么是HDFS？？？</h2><h1 id="HDFS（分布式文件系统）"><a href="#HDFS（分布式文件系统）" class="headerlink" title="HDFS（分布式文件系统）"></a>HDFS（分布式文件系统）</h1><h2 id="HDFS全称Hadoop-Distributed-File-System-分布式文件系统。分布式文件系统-HDFS-是指被设计成适合运行在通用硬件-commodity-hardware-上的分布式文件系统。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。"><a href="#HDFS全称Hadoop-Distributed-File-System-分布式文件系统。分布式文件系统-HDFS-是指被设计成适合运行在通用硬件-commodity-hardware-上的分布式文件系统。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。" class="headerlink" title="HDFS全称Hadoop Distributed File System 分布式文件系统。分布式文件系统(HDFS)是指被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。"></a>HDFS全称Hadoop Distributed File System 分布式文件系统。分布式文件系统(HDFS)是指被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。</h2><h3 id="HDFS适合做什么？不适合做什么？"><a href="#HDFS适合做什么？不适合做什么？" class="headerlink" title="HDFS适合做什么？不适合做什么？"></a>HDFS适合做什么？不适合做什么？</h3><ul>
<li><p>适合</p>
<ul>
<li>大文件存储与访问</li>
<li>流式数据访问</li>
</ul>
</li>
<li><p>不适合</p>
<ul>
<li>大量小文件存储</li>
<li>随机写入</li>
<li>低延迟读取</li>
</ul>
</li>
</ul>
<h2 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h2><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1577384416645&di=80852bbf29eb9e254133d1720d6761b0&imgtype=jpg&src=http%3A%2F%2Fimg3.imgtn.bdimg.com%2Fit%2Fu%3D1673150748%2C2487281827%26fm%3D214%26gp%3D0.jpg" alt="Hadoop_Architecture" title="Hadoop_Architecture"></p>
<h3 id="HDFS采用了主从（Master-Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。当主服务器down掉，备服务器接替服务器工作。"><a href="#HDFS采用了主从（Master-Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。当主服务器down掉，备服务器接替服务器工作。" class="headerlink" title="HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。当主服务器down掉，备服务器接替服务器工作。"></a>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。当主服务器down掉，备服务器接替服务器工作。</h3><h3 id="HDFS架构包含三个部分：NameNode，DataNode，Client。"><a href="#HDFS架构包含三个部分：NameNode，DataNode，Client。" class="headerlink" title="HDFS架构包含三个部分：NameNode，DataNode，Client。"></a>HDFS架构包含三个部分：NameNode，DataNode，Client。</h3><p>NameNode：NameNode用于存储、生成文件系统的元数据。运行一个实例。<br>DataNode：DataNode用于存储实际的数据，将自己管理的数据块上报给NameNode ，运行多个实例。<br>Client：支持业务访问HDFS，从NameNode ,DataNode获取数据返回给业务。多个实例，和业务一起运行。</p>
<h3 id="HDFS数据写入流程如下："><a href="#HDFS数据写入流程如下：" class="headerlink" title="HDFS数据写入流程如下："></a>HDFS数据写入流程如下：</h3><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1577383366145&di=c1563dd456a2fbe5d0b5b3ce222bac2f&imgtype=jpg&src=http%3A%2F%2Fimg2.imgtn.bdimg.com%2Fit%2Fu%3D890888027%2C3188327475%26fm%3D214%26gp%3D0.jpg" alt="Hadoop_write" title="Hadoop_write"></p>
<p>1.Client跟NameNode通信请求上传文件，NameNode检查目标文件是否存在，父目录是否存在</p>
<p>2.NameNode返回是否可以上传</p>
<p>3.Client会先对文件进行切分，比如一个block块128M，文件300M就会被切分成3个块，两个128M，一个44M。请求第一个block该传输到哪些DN服务器上。</p>
<p>4.NameNode返回DateNode的服务器。</p>
<p>5.Client请求一个台DataNode上传数据，第一个DataNode收到请求会继续调用第二个DN，然后第二个调用第三个DataNode,将整个pipeline建立完成，逐级返回客户端。</p>
<p>6.Client开始传输block(先从磁盘读取数据存储到一个本地内存缓存)，以packet为单位（一个packet为64kb）,写入数据的时候datanode会进行数据校验，并不是通过packet为单位校验，而是以chunk为单位校验（512byte）,第一个DateNode收到第一个packet就会传给第二台，第二台传给第三台；第一台每传一个packet就会放入一个应答队列等待应答。</p>
<p>7.当一个block传输完成时，Client再次请求NameNode上传第二个block的服务器。<br>8.当3个节点(默认)全部上传完成时，释放资源，完成上传。</p>
<h3 id="HDFS数据读流程如下："><a href="#HDFS数据读流程如下：" class="headerlink" title="HDFS数据读流程如下："></a>HDFS数据读流程如下：</h3><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1577383819984&di=7050765ff6932eb91160cd067b2c413c&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180625%2Fe979feee7c4344d2a7c52b9c980d09bd.jpeg" alt="Hadoop_read" title="Hadoop_write"></p>
<p>1.跟NameNode通信查询元数据(block所在的DN的节点)，找到文件块所在的DN的服务器。</p>
<p>2.挑选一台DateNode（就近原则，然后随机）服务器，请求建立socket流。</p>
<p>3.DateNode开始发送数据（从磁盘里读取数据放入流，一packet为单位做校验）</p>
<p>4.客户端以packet为单位接收，现在本地缓存，然后写入目标文件中，后面的block块就相当于append到前面的block块，最后合成最终需要的文件。</p>
]]></content>
      <tags>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
</search>
